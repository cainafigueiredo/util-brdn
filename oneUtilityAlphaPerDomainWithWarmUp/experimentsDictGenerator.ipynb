{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import itertools\n",
    "import numpy as np\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from utils.experiment import loadDatabase\n",
    "from utils.utils import getHashFromDict\n",
    "\n",
    "randomSeed = 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"../data/preprocessed\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Cross-Validation for Transfer Setting**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It assumes that there is not enough target data for learning and resorts to a related domain (source) to augment the training data. To simulate low target data availability, each iteration of our cross validation for transfer settings selects one fold for training and the remaining for test. This is the opposite of traditional cross validation. \n",
    "\n",
    "In our transfer experiments, we also consider learning from scratch. In this case, the learning only relies on the limited target data, as simulated by our cross validation procedure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXPERIMENTS_BASE_PATH = \"./experiments/crossValidation\"\n",
    "MODELS = [\"OriginalRDNBoost\", \"TransferLearning\", \"TreeBoostler\", \"AnalogousToOriginalRDNBoost\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getExperimentID(experimentDict):\n",
    "    experimentID = getHashFromDict(experimentDict)\n",
    "    return experimentID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "commonFixedParams = {\n",
    "    \"path\": EXPERIMENTS_BASE_PATH,\n",
    "    \"randomSeed\": randomSeed,\n",
    "    \"numberOfClauses\": 8,\n",
    "    \"numberOfCycles\": 100,\n",
    "    \"maxTreeDepth\": 3,\n",
    "    \"nEstimators\": 10,\n",
    "    \"nodeSize\": 2,\n",
    "    \"negPosRatio\": 2,\n",
    "    \"maxFailedNegSamplingRetries\": 50,\n",
    "    \"ignoreSTDOUT\": True,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "transferDatasetParams = [\n",
    "    # IMDB to Cora\n",
    "    {\n",
    "        \"sourceDatabase\": {\n",
    "            \"path\": f\"{DATA_PATH}/imdb\",\n",
    "            \"targetPredicate\": None, # Default: workedunder/2\n",
    "            \"resetTargetPredicate\": False\n",
    "        },\n",
    "\n",
    "        \"targetDatabase\": {\n",
    "            \"path\": f\"{DATA_PATH}/cora\",\n",
    "            \"targetPredicate\": None, # Default: samevenue/2\n",
    "            \"resetTargetPredicate\": False\n",
    "        },\n",
    "\n",
    "        \"useRecursion\": False\n",
    "    },\n",
    "\n",
    "    # Cora to IMDB\n",
    "    {\n",
    "        \"sourceDatabase\": {\n",
    "            \"path\": f\"{DATA_PATH}/cora\",\n",
    "            \"targetPredicate\": None, # Default: samevenue/2\n",
    "            \"resetTargetPredicate\": False\n",
    "        },\n",
    "\n",
    "        \"targetDatabase\": {\n",
    "            \"path\": f\"{DATA_PATH}/imdb\",\n",
    "            \"targetPredicate\": None, # Default: workedunder/2\n",
    "            \"resetTargetPredicate\": False\n",
    "        },\n",
    "\n",
    "        \"useRecursion\": False\n",
    "    },\n",
    "\n",
    "    # Twitter to Yeast\n",
    "    {\n",
    "        \"sourceDatabase\": {\n",
    "            \"path\": f\"{DATA_PATH}/twitter\",\n",
    "            \"targetPredicate\": None, # Default: accounttype/2\n",
    "            \"resetTargetPredicate\": False\n",
    "        },\n",
    "\n",
    "        \"targetDatabase\": {\n",
    "            \"path\": f\"{DATA_PATH}/yeast\",\n",
    "            \"targetPredicate\": None, # Default: proteinclass/2\n",
    "            \"resetTargetPredicate\": False\n",
    "        },\n",
    "\n",
    "        \"useRecursion\": True\n",
    "    },\n",
    "\n",
    "    # Yeast to Twitter\n",
    "    {\n",
    "        \"sourceDatabase\": {\n",
    "            \"path\": f\"{DATA_PATH}/yeast\",\n",
    "            \"targetPredicate\": None, # Default: proteinclass/2\n",
    "            \"resetTargetPredicate\": False\n",
    "        },\n",
    "\n",
    "        \"targetDatabase\": {\n",
    "            \"path\": f\"{DATA_PATH}/twitter\",\n",
    "            \"targetPredicate\": None, # Default: accounttype/2\n",
    "            \"resetTargetPredicate\": False\n",
    "        },\n",
    "        \n",
    "        \"useRecursion\": True\n",
    "    },\n",
    "\n",
    "    # IMDB to UWCSE\n",
    "    {\n",
    "        \"sourceDatabase\": {\n",
    "            \"path\": f\"{DATA_PATH}/imdb\",\n",
    "            \"targetPredicate\": None, # Default: workedunder/2\n",
    "            \"resetTargetPredicate\": False\n",
    "        },\n",
    "\n",
    "        \"targetDatabase\": {\n",
    "            \"path\": f\"{DATA_PATH}/uwcse\",\n",
    "            \"targetPredicate\": None, # Default: advisedby/2\n",
    "            \"resetTargetPredicate\": False\n",
    "        },\n",
    "\n",
    "        \"useRecursion\": False\n",
    "    },\n",
    "\n",
    "    # UWCSE to IMDB\n",
    "    {\n",
    "        \"sourceDatabase\": {\n",
    "            \"path\": f\"{DATA_PATH}/uwcse\",\n",
    "            \"targetPredicate\": None, # Default: advisedby/2\n",
    "            \"resetTargetPredicate\": False\n",
    "        },\n",
    "\n",
    "        \"targetDatabase\": {\n",
    "            \"path\": f\"{DATA_PATH}/imdb\",\n",
    "            \"targetPredicate\": None,  # Default: workedunder/2\n",
    "            \"resetTargetPredicate\": False\n",
    "        },\n",
    "\n",
    "        \"useRecursion\": False\n",
    "    },\n",
    "\n",
    "    # NELL Finances to NELL Sports\n",
    "    {\n",
    "        \"sourceDatabase\": {\n",
    "            \"path\": f\"{DATA_PATH}/nell_finances\",\n",
    "            \"targetPredicate\": None, # Default: companyeconomicsector/2\n",
    "            \"resetTargetPredicate\": False\n",
    "        },\n",
    "\n",
    "        \"targetDatabase\": {\n",
    "            \"path\": f\"{DATA_PATH}/nell_sports\",\n",
    "            \"targetPredicate\": None, # Default: teamplayssport/2\n",
    "            \"resetTargetPredicate\": False\n",
    "        },\n",
    "\n",
    "        \"useRecursion\": True\n",
    "    },\n",
    "\n",
    "    # NELL Sports to NELL Finances\n",
    "    {\n",
    "        \"sourceDatabase\": {\n",
    "            \"path\": f\"{DATA_PATH}/nell_sports\",\n",
    "            \"targetPredicate\": None, # Default: teamplayssport/2\n",
    "            \"resetTargetPredicate\": False\n",
    "        },\n",
    "\n",
    "        \"targetDatabase\": {\n",
    "            \"path\": f\"{DATA_PATH}/nell_finances\",\n",
    "            \"targetPredicate\": None, # Default: companyeconomicsector/2\n",
    "            \"resetTargetPredicate\": False\n",
    "        },\n",
    "        \n",
    "        \"useRecursion\": True\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getNextModelParams(model: str, mappings = None):\n",
    "    modelParams = []\n",
    "\n",
    "    if model == \"OriginalRDNBoost\":\n",
    "        modelParams = [{\"runOriginalRDNBoost\": True}]   \n",
    "\n",
    "    elif model == \"AnalogousToOriginalRDNBoost\":\n",
    "        modelParams = [{\"runAnalogousToOriginalRDNBoost\": True}]\n",
    "\n",
    "    elif model == \"TransferLearning\":\n",
    "        utilityAlphaValues = [0, 0.3, 0.6, 1, 1.3]\n",
    "        utilityAlphaList = [\n",
    "            {\n",
    "                \"sourceUtilityAlpha\": sourceAlpha,\n",
    "                \"targetUtilityAlpha\": targetAlpha\n",
    "            } for sourceAlpha, targetAlpha in itertools.product(utilityAlphaValues, utilityAlphaValues)\n",
    "        ]\n",
    "        \n",
    "        utilityAlphaSetIterList = [{\"utilityAlphaSetIter\": iteration} for iteration in [1,3,5,7]]\n",
    "\n",
    "        weightList = [\n",
    "            {\n",
    "                \"weight\": {\n",
    "                    \"strategy\": \"scalar\",\n",
    "                    \"parameters\": {\n",
    "                        \"weight\": 1\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        ]\n",
    "\n",
    "        mappingList = [\n",
    "            {    \n",
    "                \"mapping\": {\n",
    "                    \"relationMapping\": mapping[0],\n",
    "                    \"termTypeMapping\": mapping[1]\n",
    "                }\n",
    "            } for mapping in mappings\n",
    "        ]\n",
    "\n",
    "        modelParams = [\n",
    "            {\n",
    "                \"runTransferLearning\": True,\n",
    "                **utilityParams,\n",
    "                **utilityAlphaSetIterList,\n",
    "                **weightParams, \n",
    "                **mappingParams,\n",
    "            } for utilityParams, utilityAlphaSetIterList, weightParams, mappingParams in itertools.product(\n",
    "                utilityAlphaList, \n",
    "                utilityAlphaSetIterList,\n",
    "                weightList, \n",
    "                mappingList\n",
    "            )\n",
    "        ]\n",
    "\n",
    "    elif model == \"TreeBoostler\":\n",
    "        modelParams = [\n",
    "            {\n",
    "                \"runTreeBoostler\": True,\n",
    "                \"maxRevisionIterations\": 2,\n",
    "                \"searchArgPermutation\": True,\n",
    "                \"allowSameTargetMap\": False,\n",
    "                \"refine\": refine,\n",
    "            } for refine in [True, False]\n",
    "        ]\n",
    "\n",
    "    else:\n",
    "        raise ValueError(f\"{model} is not a valid model.\")\n",
    "\n",
    "    for params in modelParams:\n",
    "        yield params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(randomSeed)\n",
    "maxMappings = 5\n",
    "experiments = []\n",
    "for datasetParams in transferDatasetParams:\n",
    "    sourceDB = loadDatabase(\n",
    "        datasetParams[\"sourceDatabase\"][\"path\"], \n",
    "        targetPredicate = datasetParams[\"sourceDatabase\"][\"targetPredicate\"],\n",
    "        resetTargetPredicate = datasetParams[\"sourceDatabase\"][\"resetTargetPredicate\"],\n",
    "        useRecursion = datasetParams[\"useRecursion\"]\n",
    "    )\n",
    "    targetDB = loadDatabase(\n",
    "        datasetParams[\"targetDatabase\"][\"path\"], \n",
    "        targetPredicate = datasetParams[\"targetDatabase\"][\"targetPredicate\"],\n",
    "        resetTargetPredicate = datasetParams[\"targetDatabase\"][\"resetTargetPredicate\"],\n",
    "        useRecursion = datasetParams[\"useRecursion\"]\n",
    "    )\n",
    "    \n",
    "    mappings = sourceDB.findAllValidMappings(targetDB)\n",
    "    np.random.shuffle(mappings)\n",
    "    mappings = mappings[:maxMappings]\n",
    "    \n",
    "    for model in MODELS:\n",
    "        experimentID = None\n",
    "        for modelParams in getNextModelParams(model = model, mappings = mappings):\n",
    "            experimentDict = {\n",
    "                **commonFixedParams, \n",
    "                **datasetParams,\n",
    "                **modelParams\n",
    "            }\n",
    "\n",
    "            experimentID = getExperimentID(experimentDict)\n",
    "            experimentDict[\"id\"] = experimentID\n",
    "            \n",
    "            experiments.append(experimentDict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4032"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(experiments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"experiments-transferCrossValidation.json\", \"w\") as f:\n",
    "    json.dump(experiments, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Traditional Cross-Validation (no transfer)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It consists of performing traditional k-fold cross validation on the target data. In other words, we consider learning from scratch with enough target data for learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXPERIMENTS_BASE_PATH = \"./experiments/noTransferCrossValidation\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getExperimentID(experimentDict):\n",
    "    experimentID = getHashFromDict(experimentDict)\n",
    "    return experimentID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "commonFixedParams = {\n",
    "    \"path\": EXPERIMENTS_BASE_PATH,\n",
    "    \"randomSeed\": randomSeed,\n",
    "    \"numberOfClauses\": 8,\n",
    "    \"numberOfCycles\": 100,\n",
    "    \"maxTreeDepth\": 3,\n",
    "    \"nEstimators\": 10,\n",
    "    \"nodeSize\": 2,\n",
    "    \"negPosRatio\": 2,\n",
    "    \"maxFailedNegSamplingRetries\": 50,\n",
    "    \"ignoreSTDOUT\": True,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasetParams = [\n",
    "    # Cora\n",
    "    {\n",
    "        \"databasePath\": f\"{DATA_PATH}/cora\",\n",
    "        \"targetPredicate\": None, # Default: samevenue/2\n",
    "        \"resetTargetPredicate\": False,\n",
    "        \"useRecursion\": False\n",
    "    },\n",
    "\n",
    "    # IMDB\n",
    "    {\n",
    "        \"databasePath\": f\"{DATA_PATH}/imdb\",\n",
    "        \"targetPredicate\": None, # Default: workedunder/2\n",
    "        \"resetTargetPredicate\": False,\n",
    "        \"useRecursion\": False\n",
    "    },\n",
    "\n",
    "    # Yeast\n",
    "    {\n",
    "        \"databasePath\": f\"{DATA_PATH}/yeast\",\n",
    "        \"targetPredicate\": None, # Default: proteinclass/2\n",
    "        \"resetTargetPredicate\": False,\n",
    "        \"useRecursion\": True\n",
    "    },\n",
    "\n",
    "    # Twitter\n",
    "    {\n",
    "        \"databasePath\": f\"{DATA_PATH}/twitter\",\n",
    "        \"targetPredicate\": None, # Default: accounttype/2\n",
    "        \"resetTargetPredicate\": False,       \n",
    "        \"useRecursion\": True\n",
    "    },\n",
    "\n",
    "    # UWCSE\n",
    "    {\n",
    "        \"databasePath\": f\"{DATA_PATH}/uwcse\",\n",
    "        \"targetPredicate\": None, # Default: advisedby/2\n",
    "        \"resetTargetPredicate\": False,\n",
    "        \"useRecursion\": False\n",
    "    },\n",
    "\n",
    "    # NELL Sports\n",
    "    {\n",
    "        \"databasePath\": f\"{DATA_PATH}/nell_sports\",\n",
    "        \"targetPredicate\": None, # Default: teamplayssport/2\n",
    "        \"resetTargetPredicate\": False,\n",
    "        \"useRecursion\": True\n",
    "    },\n",
    "\n",
    "    # NELL Finances\n",
    "    {\n",
    "        \"databasePath\": f\"{DATA_PATH}/nell_finances\",\n",
    "        \"targetPredicate\": None, # Default: companyeconomicsector/2\n",
    "        \"resetTargetPredicate\": False,      \n",
    "        \"useRecursion\": True\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments = []\n",
    "for params in datasetParams:    \n",
    "    experimentDict = {\n",
    "        **commonFixedParams, \n",
    "        **params,\n",
    "    }\n",
    "\n",
    "    experimentID = getExperimentID(experimentDict)\n",
    "    experimentDict[\"id\"] = experimentID\n",
    "    \n",
    "    experiments.append(experimentDict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(experiments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"experiments-noTransferCrossValidation.json\", \"w\") as f:\n",
    "    json.dump(experiments, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Transfer with Noisy Source**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this experiment, we perform transfer learning from a noisy source to a target domain. To control the noise intensity, we build both target and source sets from the same dataset. This allow us to bypass the challenge of finding a good mapping. Before cobining the source and target data, we randomly add, remove or change the types of the relations on the source. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXPERIMENTS_BASE_PATH = \"./experiments/noisyTransferLearning\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getExperimentID(experimentDict):\n",
    "    experimentID = getHashFromDict(experimentDict)\n",
    "    return experimentID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "commonFixedParams = {\n",
    "    \"path\": EXPERIMENTS_BASE_PATH,\n",
    "    \"randomSeed\": randomSeed,\n",
    "    \"numberOfClauses\": 8,\n",
    "    \"numberOfCycles\": 100,\n",
    "    \"maxTreeDepth\": 3,\n",
    "    \"nEstimators\": 10,\n",
    "    \"nodeSize\": 2,\n",
    "    \"negPosRatio\": 2,\n",
    "    \"maxFailedNegSamplingRetries\": 50,\n",
    "    \"ignoreSTDOUT\": True,\n",
    "    \"trainNSplits\": 5,\n",
    "    \"trainSourceSplits\": 4\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasetParams = [\n",
    "    # NELL Finances\n",
    "    {\n",
    "        \"databasePath\": f\"{DATA_PATH}/nell_finances\",\n",
    "        \"targetPredicate\": None, # Default: companyeconomicsector/2\n",
    "        \"resetTargetPredicate\": False,      \n",
    "        \"useRecursion\": True\n",
    "    }, \n",
    "\n",
    "    # Yeast\n",
    "    {\n",
    "        \"databasePath\": f\"{DATA_PATH}/yeast\",\n",
    "        \"targetPredicate\": None, # Default: proteinclass/2\n",
    "        \"resetTargetPredicate\": False,\n",
    "        \"useRecursion\": True\n",
    "    },\n",
    "\n",
    "    # NELL Sports\n",
    "    {\n",
    "        \"databasePath\": f\"{DATA_PATH}/nell_sports\",\n",
    "        \"targetPredicate\": None, # Default: teamplayssport/2\n",
    "        \"resetTargetPredicate\": False,\n",
    "        \"useRecursion\": True\n",
    "    },\n",
    "\n",
    "    # Cora\n",
    "    {\n",
    "        \"databasePath\": f\"{DATA_PATH}/cora\",\n",
    "        \"targetPredicate\": None, # Default: samevenue/2\n",
    "        \"resetTargetPredicate\": False,\n",
    "        \"useRecursion\": False\n",
    "    },\n",
    "\n",
    "    # UWCSE\n",
    "    {\n",
    "        \"databasePath\": f\"{DATA_PATH}/uwcse\",\n",
    "        \"targetPredicate\": None, # Default: advisedby/2\n",
    "        \"resetTargetPredicate\": False,\n",
    "        \"useRecursion\": False\n",
    "    },\n",
    "\n",
    "    # Twitter\n",
    "    {\n",
    "        \"databasePath\": f\"{DATA_PATH}/twitter\",\n",
    "        \"targetPredicate\": None, # Default: accounttype/2\n",
    "        \"resetTargetPredicate\": False,       \n",
    "        \"useRecursion\": True\n",
    "    },\n",
    "\n",
    "    # IMDB\n",
    "    {\n",
    "        \"databasePath\": f\"{DATA_PATH}/imdb\",\n",
    "        \"targetPredicate\": None, # Default: workedunder/2\n",
    "        \"resetTargetPredicate\": False,\n",
    "        \"useRecursion\": False\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getNextModelParams():\n",
    "    utilityAlphaValues = [0, 0.3, 0.6, 1, 1.3]\n",
    "    utilityAlphaList = [\n",
    "        {\n",
    "            \"sourceUtilityAlpha\": sourceAlpha,\n",
    "            \"targetUtilityAlpha\": targetAlpha\n",
    "        } for sourceAlpha, targetAlpha in itertools.product(utilityAlphaValues, utilityAlphaValues)\n",
    "    ]\n",
    "    \n",
    "    utilityAlphaSetIterList = [{\"utilityAlphaSetIter\": iteration} for iteration in [1]]\n",
    "\n",
    "    weightList = [\n",
    "        {\n",
    "            \"weight\": {\n",
    "                \"strategy\": \"scalar\",\n",
    "                \"parameters\": {\n",
    "                    \"weight\": 1\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    noiseStrengthValues = [(1e-5)*(2**i) for i in range(0, 15)]\n",
    "    noiseStrengthList = [{\"noiseStrength\": strength} for strength in noiseStrengthValues]\n",
    "\n",
    "    paramsGrid = [\n",
    "        {\n",
    "            **utilityParams,\n",
    "            **utilityAlphaSetIterList,\n",
    "            **weightParams, \n",
    "            **noiseStrengthParams\n",
    "        } for utilityParams, utilityAlphaSetIterList, weightParams, noiseStrengthParams in itertools.product(\n",
    "            utilityAlphaList, \n",
    "            utilityAlphaSetIterList,\n",
    "            weightList,\n",
    "            noiseStrengthList\n",
    "        )\n",
    "    ]\n",
    "\n",
    "    for params in paramsGrid:\n",
    "        yield params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments = []\n",
    "for params in datasetParams:    \n",
    "    for paramsGrid in getNextModelParams():\n",
    "        experimentDict = {\n",
    "            **commonFixedParams, \n",
    "            **params,\n",
    "            **paramsGrid\n",
    "        }\n",
    "\n",
    "        experimentID = getExperimentID(experimentDict)\n",
    "        experimentDict[\"id\"] = experimentID\n",
    "        \n",
    "        experiments.append(experimentDict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2625"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(experiments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"experiments-noisyTransferLearning.json\", \"w\") as f:\n",
    "    json.dump(experiments, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Progressive Target Data Availability**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It evaluates how target data availability impacts the performance of our instance-based transfer learning model. We only consider the best settings for each pair of source and target domains, according to the results from the cross validation for transfer settings. In particular, we define the best setting based on the AUC PR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXPERIMENTS_BASE_PATH = \"./experiments/learningCurve\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getExperimentID(experimentDict):\n",
    "    experimentID = getHashFromDict(experimentDict)\n",
    "    return experimentID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "learningFromScratchOriginalRDNBoostExpIDs = [\n",
    "    \"0726cac0b41d9aa866dbf57bd36b115ed1c50e11afedc0232f4809c47533219a\", # NELL Sports\n",
    "    \"51d101f2e9cfac1aa4edb1f463accf3f6b5d41f573f52ae1e90a28db8ad7b022\", # IMDB\n",
    "    \"6a9f022b5fc34609ec98a9898cafb1845f9e40acb61a13255e18e0fdd935f419\", # Yeast\n",
    "    \"816f88e322ad9332974b410b99743c591cfb28291770844b23d5ab2e50cf7967\", # Cora\n",
    "    \"b66e86ba8b85a4ad471123e9d4010515430a0c49c6fa23f7496e373ed78183cf\", # Twitter\n",
    "    \"bf61e2b7f32e7599b7a4c2e147a01836132f2ca951dcf02c9642f97c877c9e1a\", # Finances\n",
    "    \"c0b61053859b77b0901fecdeaad7db8405a209cd76add3a212044068dae41802\", # UW-CSE\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "learningFromScratchOriginalRDNBoostSettings = []\n",
    "for expID in learningFromScratchOriginalRDNBoostExpIDs:\n",
    "    with open(f\"./experiments/crossValidation/{expID}/setting.json\") as f:\n",
    "        expSetting = json.load(f)\n",
    "        expSetting[\"path\"] = EXPERIMENTS_BASE_PATH\n",
    "        learningFromScratchOriginalRDNBoostSettings.append(expSetting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "bestAUCPRCrossValidationExpIDs = [\n",
    "    \"bd52831309ada286d62e64cf24e949319f73c548fd60103f5c595d2a3b80e1c2\", # IMDB to Cora\n",
    "    \"396a63c068864d171cb3eeb5c9340cea81e4e0ce00592bd492485edfba59c5ff\", # Cora to IMDB\n",
    "    \"f3ae43b9215c2493380521cec736ff40fe7b9e98a9e093af156ec3ca880807cc\", # IMDB to UW-CSE\n",
    "    \"6686ac04ddaf3e507af9c6b94b8f868e37c2d1a12fdccecaa8770b8892934d76\", # Twitter to Yeast\n",
    "    \"b45ead65a1670ade43e08d3f429838d56e21dd723ebd05a0db46df3323738b3e\", # Yeast to Twitter\n",
    "    \"9d42911e8115f7e1f34b8333583d28b0bef5ccc46bcff5a7ba664af957adef29\", # NELL Sports to NELL Finances\n",
    "    \"54ab7a686188f35592556347bf5251921a8ade4adb0ab22b7bcc078c9800b684\", # NELL Finances to NELL Sports\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "bestAUCPRCrossValidationSettings = []\n",
    "for expID in bestAUCPRCrossValidationExpIDs:\n",
    "    with open(f\"./experiments/crossValidation/{expID}/setting.json\") as f:\n",
    "        expSetting = json.load(f)\n",
    "        expSetting[\"path\"] = EXPERIMENTS_BASE_PATH\n",
    "        bestAUCPRCrossValidationSettings.append(expSetting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "worstAUCPRCrossValidationExpIDs = [\n",
    "    \"8f1f2f42ac13df76c11fdd4fc2012f1a02d64609e64fa0258d1e34c50a28301a\", # IMDB to Cora\n",
    "    \"51f933537100240bacb4f7a6341c4f77a9b233a4e493d5938c556dd990ddb4f1\", # Cora to IMDB\n",
    "    \"ed84223eca8dea790d61b5ebed802d1bb652cf449866cd8d00740f4e6423c7fb\", # IMDB to UW-CSE\n",
    "    \"1083b5b58bc7c476d69917dc5a42cc31fdbc6910b4a51102867b0c71be10da74\", # Twitter to Yeast\n",
    "    \"82685ff50ecd1e70faeec5f45a5feb4702b3d939876d71d7f9de55684df757ed\", # Yeast to Twitter\n",
    "    \"81cb6ed097c877693916a86800636138255b05b772fdcd024958faa184cd04e5\", # NELL Sports to NELL Finances\n",
    "    \"a375d163f0e4c861940f9cbcceb0c5254eaa606a9d38144abce4a493d700af92\", # NELL Finances to NELL Sports\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "worstAUCPRCrossValidationSettings = []\n",
    "for expID in worstAUCPRCrossValidationExpIDs:\n",
    "    with open(f\"./experiments/crossValidation/{expID}/setting.json\") as f:\n",
    "        expSetting = json.load(f)\n",
    "        expSetting[\"path\"] = EXPERIMENTS_BASE_PATH\n",
    "        worstAUCPRCrossValidationSettings.append(expSetting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiments = bestAUCPRCrossValidationSettings + worstAUCPRCrossValidationSettings + learningFromScratchOriginalRDNBoostSettings\n",
    "len(experiments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"experiments-learningCurve.json\", \"w\") as f:\n",
    "    json.dump(experiments, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
